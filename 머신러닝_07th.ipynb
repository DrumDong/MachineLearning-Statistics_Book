{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "머신러닝_07th.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdjUNi1koY7muk+d/n/A7+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K1gHdjtN151",
        "colab_type": "text"
      },
      "source": [
        "What is a good model?\n",
        "- 현재 데이터를 잘 설명하는 모델\n",
        "\n",
        "![대체 텍스트](https://miro.medium.com/max/968/1*RvmKLhZVbcJu8qj5JpCd1w.png)\n",
        " - Training error를 minimize하는 모델 -> 편향(Bias)와 분산(Variance)를 줄이는 것\n",
        " - 상황에 따라 편향성을 더 낮춰야할지 분산을 더 낮춰야할지에 대한 중요도가 다름\n",
        "- 미래 데이터에 대한 예측 성능이 좋은 모델\n",
        "\n",
        "---\n",
        "- Expected MSE를 줄이려면 bias, variance, 혹은 둘다 낮춰야함\n",
        "- 그렇지 못하면 둘 중에 하나라도 작으면 좋음\n",
        "- Bias가 증가되더라도 variance 감소폭이 더 크다면 expected MSE는 감소(예측 성능 증가)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDoKv-dJexYx",
        "colab_type": "text"
      },
      "source": [
        "# How to reduce Variacne?\n",
        "- 최소제곱법(MSE를 최소화하는 회귀계수 계산)에서 구해진 회귀계수는 Unbiased estimator 중 가장 분산이 작은 estimator (가우스-마르코브 이론)\n",
        "\n",
        "-> 어느정도의 Bias를 갖게 하더라도 Variance를 최대한 작게 할 수 있는 방법이 있지 않을까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfBSzBXzfgjH",
        "colab_type": "text"
      },
      "source": [
        "## Subset Selection\n",
        "- 전체 p개의 설명변수(X)중 일부 k개만을 사용하여 회귀계수를 추정하는 방법\n",
        "- 전체 변수 중 일부만을 선택함에 따라 bias가 증가할 수 있지만 variance가 감소함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2XFZXAhf4dX",
        "colab_type": "text"
      },
      "source": [
        "## Regularization Concept (정규화)\n",
        "![대체 텍스트](https://www.researchgate.net/profile/Peter_Csurcsia/publication/327955521/figure/fig3/AS:676162485383168@1538221107512/llustration-of-the-concept-of-the-regularization-technique-with-respect-to-the-classical.png)\n",
        "\n",
        "- 모델이 복잡해질수록 Bias가 줄어들어 Train데이터에 대한 예측력이 올라가지만 Variance가 커지기 때문에 Test데이터에 대한 예측력이 떨어짐.\n",
        "\n",
        "![대체 텍스트](https://miro.medium.com/max/1346/1*HP4RnnX-S3qyb4qrmI0MVQ.png)\n",
        "\n",
        "- 이를 해결하기 위해 B(회귀계수)에 제약조건을 부여\n",
        "- 람다: 제약을 주는 역할(하이퍼 파라미터)\n",
        "---\n",
        "\n",
        "- 람다가 굉장히 크면 -> 회귀절편만 빼고 모든 회귀계수가 0으로 가까워지기 때문에 General해지지만 현재데이터에 Underfitting이 됨\n",
        "- 람다가 굉장히 작아지면 -> 모든 회귀계수 값들이 유지되기 때문에 Overfitting이 될 것임."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R880KhBPm1b2",
        "colab_type": "text"
      },
      "source": [
        "# Rigde Regression\n",
        "- 회귀계수 제곱(L2)의 합을 제한\n",
        "\n",
        "![대체 텍스트](https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png)\n",
        "\n",
        "![대체 텍스트](https://t1.daumcdn.net/cfile/tistory/2624DF50592CB1E80B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG8YxB3ZqB60",
        "colab_type": "text"
      },
      "source": [
        "# Lasso (Least Absolute Shrinkage and Selection Operator)\n",
        "- 변수 선택 가능\n",
        "- 회귀 계수 B의 L1-norm을 제한\n",
        "\n",
        "![대체 텍스트](https://t1.daumcdn.net/cfile/tistory/99B45E355C90F8532C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF6UyQQ_rHTv",
        "colab_type": "text"
      },
      "source": [
        "Lasso Solution Path\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/xsa2fNQ.png)\n",
        "\n",
        "- 마름모 꼴이기 떄문에 불연속 점이 존재함.\n",
        "---\n",
        "- Ridge와 달리 Lasso는 closed form solution을 구현하는 것이 불가능(L1-norm 미분 불가능)\n",
        " - 수치 최적화 방법을 적용해야함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cL2JtserKLj",
        "colab_type": "text"
      },
      "source": [
        "## Lasso Parameter\n",
        "- 람다 값을 어떻게 설정할 것인가? <-> 몇 개의 변수를 선택할 것인가?\n",
        " - 큰 람다 값: 적은변수, 간단한 모델, 해석 easy, 높은 학습 오차(Underfitting 위험 증가)\n",
        " - 작은 람다 값: 많은변수,복잡한 모델, 해석 어려움, 낮은 학습 오차(overfitting 위험 증가)\n",
        "\n",
        "![대체 텍스트](https://www.cvxpy.org/_images/lasso_regression_11_0.svg)\n",
        "\n",
        "---\n",
        "- 데이터가 달라질 떄 마다 변수선택이 달라지지는 않을까?\n",
        " - Train, Test 데이터에 따라 변수선택 결과가 달라질 수 있음 얼마나 달라질까?\n",
        "  1. 데이터가 바뀔때마다 L1규제로 인한 회귀계수 변화의 폭이 얼마나 큰지 확인하면 됨."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdquP4qdzxep",
        "colab_type": "text"
      },
      "source": [
        "Solution Paths Ridge and Lasso\n",
        "- Ridge와 Lasso 모두 t가 작아짐(람다가 커짐)에 따라 모든 계수의 크기가 감소\n",
        "- Lasso: 예측에 중요하지 않은 변수가 더 빠르게 감소, t가 작아짐에 따라 예측에 중요하지 않은 변수가 0이 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-pvrZ1w0bKH",
        "colab_type": "text"
      },
      "source": [
        "Ridge vs Lsso\n",
        "- Ridge\n",
        "  - Ridge는 변수 간 상관관계가 높은 상황에서 좋은 예측 성능\n",
        "  - 크기가 큰 변수를 우선적으로 줄이는 경향이 있음 \n",
        "\n",
        "- Lasso\n",
        " - 변수 간 상관관계가 높은 상황에서 ridge에 비해 상대적으로 예측 성능이 떨어짐\n",
        " - 변수 간 상관관계가 높으니까, 회귀계수의 박스플롯이 크게 나타탐(값에 따라 회귀계수가 많이 바뀐다는 뜻)\n",
        "> -> 변수 간 상관관계를 반영할 수 있는 방법 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qmImokX1Biq",
        "colab_type": "text"
      },
      "source": [
        "# Elastic Net\n",
        "- Ridge + Lasso (L1-and L- regularization)\n",
        "- 상관관계 큰 변수를 동시에 선택/배제하는 특성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOXP7gq2qJN",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://lh3.googleusercontent.com/proxy/GaKNfhpWKb8QEjAhEtAVXZqGKsEnxXfgYv33q7T4pR3GutFF2Su87pzLpV4LCppPXb53S5Yt8Lt-0iVd2ekoI-R1ms04S7DWfq802anygfokIU2F-SiNDOI)\n",
        "\n",
        "- Grouping Effect를 적용하기 때문에 상관관계가 큰 변수끼리는 같은 회귀계수를 유지하게 되도록 만듬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPtqTGE-4mnf",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://flonelin.files.wordpress.com/2017/03/24.png)\n",
        "\n",
        "![대체 텍스트](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTnmXxn6OQC13Sg1YpAHb-jdvUsvp09fy7cP9zYc5n6Me-OnpLk&usqp=CAU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxiAnylY5S7R",
        "colab_type": "text"
      },
      "source": [
        "# Regularization with Prior Knowledge\n",
        "- 상관관계 높은 변수를 동시에 선택 : Elastic Net\n",
        "- 인접한 변수들 동시에 선택 : Fused Lasso\n",
        "- 사용자가 정의한 그룹 단위로 변수 선택 : Group Lasso\n",
        "- 사용자가 정의한 그래프의 연결 관계에 따라 변수 선택 : Grace"
      ]
    }
  ]
}